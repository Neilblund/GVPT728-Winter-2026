---
title: "Matching"
format:
  html:
    theme: [default, custom_styles]
    df-print: paged
    smaller: true
    toc: true
    toc-location: left
    toc-depth: 3
    embed-resources: true
    code-link: true
    code-tools: true
code-annotations: select
editor: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE }
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```




# Data

We'll load up the Lalonde data. Our goal here is to see if we can replicate or at least get close to the correct estimate in Lalonde's 1986 paper using observational data. According to his model, the actual effect for the job training program was a $1,794 increase in the subject's wages in 1978. 

```{r}
library(tidyverse)
library(MatchIt)
library(WeightIt)
library(gtsummary)
library(modelsummary)
library(GGally)
library(marginaleffects)
library(cobalt)
data(lalonde, package="MatchIt")
```



As usual a good starting point here is to get some basic descriptive stats on our variables. 

::: panel-tabset
## Factors

```{r fig.width=8, fig.height=8}

lalonde|>
  select(treat, educ, married, nodegree, race)|>
  mutate(treat = factor(treat, labels=c("control", "treatment")),
         married = factor(married, labels=c('single','married')),
         nodegree = factor(nodegree, labels=c('degree','no degree'))
         )|>
  ggpairs(aes(fill=treat, color=treat), upper='blank') +
  theme_bw() +
  scale_fill_brewer(palette='Dark2') +
  scale_color_brewer(palette='Dark2')


```

## Continuous

```{r fig.width=8, fig.height=8}
lalonde|>
  select(treat, age, re74, re75, re78)|>
  mutate(treat = factor(treat, labels=c("control", "treatment")))|>
  ggpairs(aes(fill=treat, color=treat), upper='blank') +
  theme_bw() +
  scale_fill_brewer(palette='Dark2') +
  scale_color_brewer(palette='Dark2')


```
:::

# Regression

We'll start with regression based estimates. The first model includes no controls, and the second includes controls for age, education, marital status, past income, degree status, and race: 


```{r}
# the uncontrolled regression
mod0<-lm(re78 ~ treat, data=lalonde)
mod1<-lm(re78 ~ treat + age + educ + married  + re74 + re75+ nodegree +race,data=lalonde)


modelsummary(list("treatment only"  =mod0, 
                        "treatment + controls" = mod1),
             estimate  = "{estimate}",  
             fmt = fmt_significant(),
             statistic ='conf.int',
             conf_level = .95,
             gof_omit = 'F|RMSE|R2$|AIC|Log.Lik.', # remove some model stats 
             # add a title
             title = "DV: Wages"
             )

```

# Matching methods



## Mahalanobis Scores

You can get Mahalanobis score matches by using `method="nearest"` and `distance='mahalanobis'`

```{r}
ma_matched <- matchit(treat ~ age + educ +  married + race +
                    nodegree + re74 + re75, 
                    data = lalonde,
                    method = "nearest",
                    distance= 'mahalanobis',
                    replace=T,
                    ratio=5
                  )

```



Once we have our matchit object, the `Cobalt` package gives us some options for balance checking. After examining the results, you might want to go back and re-specify the model. 

```{r}

bal.tab(ma_matched, thresholds = c(m = .1), un = TRUE)

bal.plot(ma_matched)

love.plot(ma_matched)

```

Access the matched data with the `match_data` function: 

```{r}

ma_data<-match_data(ma_matched)

head(ma_data)


```

Note that a fairly large number of observations have been discarded here:

```{r}

nrow(ma_data)


```

We can use the results in our regression model. Be sure to include the weights!

```{r}

ma_fit<-lm(re78 ~ treat + age + educ +  married + race +nodegree + re74 + re75, 
   data = ma_data,
   weight = weights )
```


Finally, we want to estimate our effects with robust standard errors:

```{r}
avg_comparisons(ma_fit,
                variables = "treat",
                vcov = 'HC3'
                )

```

```{r}


modelsummary(list(
                  "Mahalanobis" = ma_fit
                  ),
             estimate  = "{estimate}",  
             fmt = fmt_significant(),
             statistic ='conf.int',
             conf_level = .95,
             vcov ='HC3',
             gof_omit = 'F|RMSE|R2$|AIC|Log.Lik.', # remove some model stats 
             # add a title
             title = "DV: Wages"
             )
```





## Coarsened Exact matching


For CEM, we'll often want to set manually set some of "cutpoints". There's no set rules here. Visual inspection of the predictors can help, and the `MatchIt` package has some defaults that can be sensible, but this is partly a judgement call: what values of the independent variables seem like they should be grouped together?

By default, observations are matched exactly on factor variables. However, you can override this by setting passing a list of levels to the `grouping` argument: 

```{r}



cem_match <- matchit(treat ~ age + educ +  married + race +
                    nodegree + re74 + re75, data = lalonde,
                  method = "cem",
                  estimand ='ATE',
                  cutpoints =list(educ = c(0,9, 12, 14)),
                  grouping = list(race = list(c("white", "hispan"),
                                              c("black")))
                  )
summary(cem_match)

```
Now we can plot our results to check out how well the matching performed: 

```{r}

plot(cem_match, 
     type = "density", 
     interactive = TRUE, 
     which.xs = ~age +
married + re75)

```
```{r}

bal.tab(cem_match, thresholds = c(m = .1), un = TRUE)

bal.plot(cem_match)

love.plot(cem_match)

```

Finally, we'll want to use the `match_data` function to extract the matched data and then estimate our model with the weights included: 

```{r}


cem_data<-match_data(cem_match)


cem_fit <- lm(re78 ~ 
            treat + age + educ + married + re74 +re75+
            nodegree+ race , data = cem_data, weights = weights)




```

```{r}

avg_comparisons(cem_fit, variables = "treat", vcov ='HC3', cluster=~subclass)

```         

```{r}

modelsummary(list(
                   "Mahalanobis" = ma_fit,
                  "Coarsened" = cem_fit
                  ),
             estimate  = "{estimate}",  
             fmt = fmt_significant(),
             statistic ='conf.int',
             conf_level = .95,
             vcov ='HC3',
             gof_omit = 'F|RMSE|R2$|AIC|Log.Lik.', # remove some model stats 
             # add a title
             title = "DV: Wages"
             )

```




##  Inverse probability weighting

Finally, we can try using inverse probability weighting on the propensity scores instead of matching. Here's how we might do that using mostly base R functions:


```{r}

# Step 1: Estimate propensity scores
fit1 <- glm(treat ~age + educ + nodegree + 
                married + race + re74 + re75 , 
            family = binomial, data =  lalonde)
lalonde$propensity <- predict(fit1, type = "response")

# calculate the inverse
lalonde<-lalonde|>
  mutate(ipw = (treat/ propensity) + ((1 - treat) / (1 - propensity)))



# Step 2: Fit weighted outcome model

m <- lm(re78 ~ treat , data = lalonde, weight = ipw)

summary(m)

avg_comparisons(m, variables = "treat", wts = lalonde$ipw, vcov = 'HC0')



```

Or we can do this using the `WeightIt` package:

```{r}
W <- weightit(treat ~ age + educ + nodegree + 
                married + race + re74 + re75, 
              data = lalonde, method = "glm", 
              estimand = "ATE")
fit <- lm_weightit(re78 ~ treat, data = lalonde,
                   weightit = W)

summary(fit, ci = TRUE)

```

Or trying using a different weighting method:


```{r}

W <- weightit(treat ~ age + educ + nodegree + 
                married + race + re74 + re75, 
              data = lalonde, method = "ebal", 
              estimand = "ATE")
fit <- lm_weightit(re78 ~ treat, data = lalonde,
                   weightit = W)

summary(fit, ci = TRUE)

avg_comparisons(fit, variables = "treat")
```

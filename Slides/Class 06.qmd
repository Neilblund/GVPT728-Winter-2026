---
title: "Random Effects Models and Panel Data"
format:
  revealjs:
    theme: [clean, custom_styles]
    df-print: paged
    smaller: true
    slide-number: true
    header: 
    header-logo: images/informal_seal_transparent.webp
    self-contained: true
code-annotations: select
slide-level: 3
---

```{r setup, include=FALSE }
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

library(tidyverse)
library(huxtable)
```

# Autocorrelation

Possible fixes (that don't require throwing out data )

. . .

::: incremental
-   Clustered Standard Errors: using either the bootstrap or a sandwich estimator to adjust the standard errors up

-   Fixed effects: make a dummy for each group and include it in the model, (potentially) eliminating the autocorrelation while also controlling for unobserved differences across groups

-   Random effects
:::

## "Random" vs. Fixed

(the terminology here is [inconsistent and contested](https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/), but no one has come up with better words yet)

-   Fixed Effects Models give every group its own y-intercept. The effects of "Texas" vs. "Tennessee" are assumed to be fixed and unrelated.

    -   In this sense, you're usually assuming a fixed effect any time you run a standard OLS model.

-   Random Effects Models assume that group intercepts are random draws from a common distribution. They can vary just like any other random variable, but they vary in a predictable way

## An example: students in classrooms

::::: columns
::: {.column width="50%"}
-   You want to estimate the effect of time spent studying on student achievement

-   But you also want to account for differences between teachers: you suspect some are slightly better than others.
:::

::: {.column width="50%"}
```{mermaid}
%%| fig-height: 1
flowchart LR
Z[School] --> A
Z --> G
Z --> L
A[Classroom 1] --> B(Student A)
A --> C(Student B)
A --> E(Student D)
G[Classroom 2] --> H(Student H)
G --> I(Student I)
G --> K(Student K)
L[Classroom 3] --> M(Student M)

```
:::
:::::

## An example: students in classrooms

You calculate some averages and your results look like this:

|                |                        |                       |
|----------------|------------------------|-----------------------|
| **Instructor** | **Number of students** | **Average SAT score** |
| Teacher 1      | 50                     | 1029                  |
| Teacher 2      | 25                     | 1020                  |
| Teacher 3      | 5                      | 1120                  |

. . .

Under a fixed effects assumption, each teacher's effect is a fixed parameter, and knowing the mean score for teacher 1 and 2 doesn't tell you anything about what the mean score should be for teacher 3.

. . .

Under a random effects assumption, the teacher effect is drawn from a larger distribution that has a central tendency and a variance. So you might look at the value for teacher 3 and conclude: "this seems implausible, in reality, this effect should probably be closer to the effect for the other two"

## An example: students in classrooms

So we could assume something like this:

$$
SAT = \text{teacher effect} + b\_\text{studying effect} \times \text{study time} + \epsilon
$$ $$ 
\epsilon \sim \mathcal{N}(0, \sigma)
$$

But we could assume a model with some kind of a "teacher effect" that also had a normal distribution like the error term:

$$ SAT = (\text{teacher effect}) + b\_\text{studying effect} \times \text{study time} + \epsilon$$

$$
\text{teacher effect} \sim \mathcal{N}(0, \tau)
$$

. . .

In the second case, we estimate a model that *slightly* biases teacher effects towards the grand mean



## Random Effects: pooling

One way to think about a random effect is that it represents a compromise between "no pooling" and "complete pooling" of regression results.

. . .

- "No pooling" would mean estimating a totally separate model for each teacher

- "Complete pooling" would mean estimating a model that totally ignores teacher effects.

- "Partial pooling" would mean estimating a model that uses a weighted average of these cases


## Random Effects: pooling



A partial pooling estimate favors "no pooling" estimate if group $j$ is large and low-variance, and favors the "complete pooling" case if group $j$ is small or high variance.


$$
\text{Estimate of random intercept } \alpha_j \approx \frac{\frac{n_j}{\sigma^2_j}}{\frac{n_j}{\sigma^2_j} + \frac{1}{\sigma^2_j}} (\bar{y_j} - \beta\bar{x}_j) + 
\frac{\frac{1}{\sigma^2_a}}{\frac{n_j}{\sigma^2_y} + \frac{1}{\sigma^2_a}} \mu_a
$$

## Random Effects: pooling


```{r, echo=FALSE}
library(Rdatasets)
library(broom)
library(lme4)
radon<-Rdatasets::rddata('radon')

ccount<-radon|>
  count(county.name)

no_pool<-split(radon, ~county.name)|>
  purrr::map(.x = _, .f=~tidy(lm(log.radon ~ 1, data=.x)))|>
  bind_rows(.id='county')|>
  left_join(ccount, by=join_by(county == county.name))

mod<-lmer(log.radon ~ 0 + (1|county.name), data=radon)
rfx<-ranef(mod)|>
  data.frame()

m1<-no_pool|>
  mutate(county = reorder(county, n),
         cfac = as.numeric(county)
         ) |>
  arrange(county)|>
  ggplot(aes(x=n, y=estimate)) + 
  geom_point()+
  labs(x='sample size', y='estimate')

mu<-mean(radon$log.radon)

rfx|>
  left_join(ccount, by=join_by(grp == county.name))|>
  select(county = grp, estimate = condval, n )|>
  mutate(type ='random effects')|>
  bind_rows(no_pool|>mutate(type='no pooling'))|>
  ggplot(aes(x=n, y=estimate)) + 
  geom_point(alpha=.4)+
  labs(x='sample size', y='estimate') +
  facet_wrap(~type) +
  theme_bw() +
  geom_hline(yintercept = mu, lty=2)


```




## Random Effects: pooling

- Random effects models will often give more plausible estimates for cases with small sample sizes - because they "pool" extreme values with small samples.

  - Think of it like estimating a batting average for a player with 2 at-bats. Is plausible they're batting 100? Or should we assume they're around the league average until we get more information?



## Random Effects

```{r, echo=FALSE}

library(tidycensus)
library(modelsummary)
counties_24<-read_csv('https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-24/refs/heads/master/2024_US_County_Level_Presidential_Results.csv')
county_data<- get_acs(geography = "county", 
                      variables = c(Pop= "B02001_001",
                                    Income = "B19013_001",
                                    White = "B03002_003", 
                                    AfAm = "B03002_004",
                                    Hisp = "B03002_012",
                                    Asian = "B03002_006"))

county_data_wide<-county_data|>
  select(-moe)|>
  pivot_wider(names_from = variable, values_from=estimate)
counties<-left_join(counties_24, county_data_wide,by=join_by(county_fips == GEOID))|>
  mutate(perc_gop = per_gop * 100, 
         Income = Income / 1000,
         White = (White/Pop) * 100,
         Hisp =(Hisp/Pop) * 100,
         AfAm = (AfAm/Pop) * 100
  )|>
  drop_na()
# adding coefficient names
coefnames<-c("Income" = "Median income ($1000)",
             "White" = "% White",
             "Hisp" = "% Hispanic",
             "AfAm" = "% African American"
             )


```

```{r, echo=TRUE}
#| output-location: column

library(fixest)
# county level election results

fmodel<-feols(perc_gop ~ Income + White + AfAm + Hisp  | state_name, data=counties)
regmodel<-feols(perc_gop ~ Income + White + AfAm + Hisp , 
                data =counties, cluster ~ state_name)

mlist<-list("No fixed effects" = regmodel, 
            'Fixed effects' = fmodel)
modelsummary(mlist, 
             estimate  = "{estimate}",  
             statistic = c("conf.int", 'std.error'),
             conf_level = .95,
             coef_rename = coefnames,
             coef_omit ='Intercept',
             gof_map = c('nobs','aic','bic', 'vcov.type',
                         'FE: state_name'
             )
)

```




## Random Effects


To specify a random effect, we can use the `lme4` package. The `(1|state_name)` says that I want to estimate random intercepts for each state:

```{r}
library(lme4)
# fixed effects version for comparison:
fixefmodel<-fixest::feols(perc_gop ~ Income + White + AfAm + Hisp  | state_name, 
                          data=counties)

ranefmodel<-lmer(perc_gop ~ Income + White + AfAm + Hisp + (1|state_name),
               data=counties
               )

```

## Random Effects


```{r, echo=FALSE}
#| output-location: slide



mlist<-list("No fixed effects" = regmodel, 
            'Fixed effects' = fmodel,
            'Random effects'  =ranefmodel
            )


modelsummary(mlist, 
             estimate  = "{estimate}",  
             statistic = c("conf.int", 'std.error'),
             conf_level = .95,
             coef_rename = coefnames,
             coef_omit ='Intercept',
             gof_map = c('nobs','aic','bic', 'vcov.type',
                         'FE: state_name'
             )
)

```




## Random Effects: additional covariates

With fixed effects models, we can't include any controls for group-level covariates because they're already in the "fixed" effect:


```{r}

library(rvest)
page<-read_html('https://en.wikipedia.org/wiki/List_of_U.S._states_by_date_of_admission_to_the_Union')

join_date<-page|>
  html_element(css='table')|>
  html_table()|>
  select(2:4)|>
  mutate(datestring = str_extract(
    `Date(admitted or ratified)`, "([A-Z][a-z]+ [0-9]{1,2}, [0-9]{4})"),
         date = mdy(datestring)
  )
counties<-counties|>
  left_join(join_date, by=join_by(state_name==State))|>
  mutate(join_year = year(date) - 1787
         
         )|>
  drop_na(join_year)

fixefmodel<-fixest::feols(perc_gop ~ Income + White + AfAm + Hisp + join_year  | state_name, 
                          data=counties)

fixefmodel

```

## Random Effects: additional covariates

But random effects models can still estimate effects for group-level characteristics:

```{r}

ranefmodel<-lmer(perc_gop ~ Income + White + AfAm + Hisp + join_year + (1|state_name),
               data=counties
               )

summary(ranefmodel)

```

## Random Effects: random slopes

We can also estimate random slopes using this same basic approach.

```{r}
#| output-location: slide

ranefmodel<-lmer(perc_gop ~  White + AfAm + Hisp + join_year + (Income |state_name),
               data=counties
               )

library(marginaleffects)
nd<-datagrid(model=ranefmodel, 
             state_name = c("Alabama", "Wyoming", "Maryland", "Virginia", "Nevada", "North Carolina"), 
             "Income" = seq(17, 170, by=20))

plot_predictions(ranefmodel, newdata=nd, by=c('Income', 'state_name')) +
  theme_bw() +
  labs(color ='State', fill='State',  y='% GOP vote')


```


## What to use

-   Fixed Effects model are best when:
    -   You want to control for un-modeled differences across groups
    -   You think groups are fundamentally "different"
    -   You don't want to control for any group-level characteristics

-   Random Effects models are preferable when:
    -   There are lots of small groups with very few members
    -   You're less worried about unmeasured heterogeneity between clusters
    -   You want to include characteristics across different "levels" or even allow the slopes to vary or certain
    observations
    


# Temporal autocorrelation

-   OLS assumes that data are independent, but your height today is not independent of your height yesterday.
-   autocorrelation: a value correlates with itself.
    -   Temporal autocorrelation is when a current value depends on a prior value.

### Problem: autocorrelation

Current values often depend on prior values. The democracy score of Paraguay in 2000 is a good predictor of current democracy scores in Paraguay.

```{r}


vdem<-vdemdata::vdem|>
  filter(e_regionpol == "2")|>
  select(country_name, year, v2x_polyarchy, e_gdppc, e_pop)

vdem|>
  filter(country_name=='Paraguay')|>
ggplot(aes(x=year, y=v2x_polyarchy)) +
  geom_line()  +
  facet_wrap(~country_name) +
  theme_minimal()


```

### Problem: autocorrelation

Lack of independence poses similar problems to what we observed with clustered samples: we will generally overstate our level of confidence in estimates. We actually have very few truly independent observations here.

```{r, echo=TRUE}

model<-vdem|>
  filter(country_name=='Paraguay')|>
  filter(year>=1995)|>
  lm(v2x_polyarchy ~ log(e_gdppc), data=_)

huxreg(model)
  




```

### Problem: autocorrelation

```{r}
plot(model)

```

### Spurious correlation

Time trends can also be a source of spuriousness. If any two variables have a time trend, they'll appear to be related in a naive regression!

::: notes
There's a general post WWII trend towards higher levels of democratization, so anything correlated with decade is likely to appear significant in a time series.
:::

```{r}

vdem|>
ggplot(aes(x=log(e_pop), y=v2x_polyarchy)) +
  geom_line()  +
  geom_smooth(method='lm', se=FALSE)+
  facet_wrap(~country_name) +
  theme_minimal() +
  xlab('logged population') +
  ylab('polyarchy score')


```



### Seasonality

Failure to account for cycles can also just lead to poor prediction in the face of complex trends. The overall trend in total airline flights looks like this:

```{r, echo=TRUE}


flights <- readRDS("C:/Users/neilb/Documents/GVPT728_Winter24/flights.RData")|>
  mutate(date =as.Date(date),
         year = year(date),
         quarter = quarter(date)
         )
ggplot(flights, aes(x=date, y=total_flights)) + 
  geom_line() +
  theme_minimal() + 
  geom_smooth(method ='lm', se=FALSE) +
  ylab("total flights") +
  xlab('date') 
```

### Seasonality

... but we do a poor job of capturing that if we're only looking at a few years of data:

```{r}


ggplot(flights, aes(x=date, y=total_flights)) + 
  geom_line() +
  theme_minimal() + 
  geom_smooth(method ='lm', se=FALSE) +
  ylab("total flights") +
  xlab('date') +
  facet_wrap(~year, scales='free')
  


```

## Potential fixes: more fixed or random effects

-   We could treat time as a factor and include it as a random effect.

-   Would could treat time as a random effect term

-   We could control for time linearly or with a polynomial or spline function

## Potential fixes: differencing

-   If data depends on prior values, taking the first difference should address it

-   difference = current_value - prior_value

### Differences

```{r}


vdem|>
  filter(country_name=='Paraguay')|>
  mutate(polyarchy = v2x_polyarchy - dplyr::lag(v2x_polyarchy),
         group='differenced'
         )|>
  bind_rows(vdem|>filter(country_name=="Paraguay")|>
              mutate(group='original',
            polyarchy = v2x_polyarchy)
            )|>
ggplot(aes(x=year, y=polyarchy, color=group)) +
  geom_line()  +
  facet_wrap(~group) +
  theme_minimal() +
  ylab('Paraguay democracy score')


```

### Differences

Taking the difference of both polyarchy and GDP in this model should eliminate the time trend effect. But it also alters what we're actually regressing.

```{r, echo=TRUE}

differenced_model<-vdem|>
  filter(country_name=='Paraguay')|>
  mutate(diff_polyarchy = v2x_polyarchy - dplyr::lag(v2x_polyarchy),
         diff_gdp = log(e_gdppc) - log(dplyr::lag(e_gdppc))
         
         )|>
  filter(year>=1995)|>
  lm(diff_polyarchy ~ diff_gdp, data=_)

huxreg("original_model"= model, "differenced_model" =differenced_model)


```

### Differences

```{r, figures-side, fig.show="hold", out.width="50%"}

plot(differenced_model)
```

### Differences: change vs. level

A change in the rate of change in the GDP with lead to a change in the rate of change of the democracy score.

```{r}
huxreg("differenced_model" =differenced_model)

```

### Differencing pros and cons

-   Pro: can account for the primary time series problem without adding any new parameters

-   Con: is actually a different model! Estimates changes, not levels!

-   Con: transforms the data in a way that makes it difficult to get predictions

## Potential fixes: lagged variable model

Another option is to include a lagged variable itself as a covariate. This is typically referred to as an autoregressive model.

```{r}
ar_model<-vdem|>
  filter(country_name=='Paraguay')|>
  arrange(year)|>
  mutate(lag_polyarchy = dplyr::lag(v2x_polyarchy),
         lag_gdp = dplyr::lag(e_gdppc)
         
         )|>
  filter(year>=1995)|>
  lm(v2x_polyarchy ~ lag_polyarchy  + log(e_gdppc)  + log(lag_gdp) , data=_)


```

### AR model

```{r}
huxreg('autoregressive' = ar_model)

```

### AR model: multiple lags

One advantage of this approach is that you can simultaneously test multiple lags, which helps if you think there's more than one source of trend.

```{r}
ar_model2<-vdem|>
  filter(country_name=='Paraguay')|>
  mutate(lag_polyarchy = dplyr::lag(v2x_polyarchy),
         lag_gdp = dplyr::lag(e_gdppc),
         lag_gdp2 = dplyr::lag(e_gdppc, 2),
         lag_polyarchy2= dplyr::lag(v2x_polyarchy, 2),
         )|>
  filter(year>=1995)|>
  lm(v2x_polyarchy ~ lag_polyarchy  + lag_polyarchy2+
       log(e_gdppc)  + 
       log(lag_gdp)  + 
       log(lag_gdp2), data=_)

huxreg(ar_model2)


```

::: notes
One advantage to this approach is that it can be more interpretable since you aren't really altering data.
:::

### AR model: pros and cons

-   Pro: allows a much more complex model specification and also tests for autocorrelation

-   Con: interpretation is weird, and it adds a lot of parameters and inevitable multicollinearity

## Other fixes

-   Including a fixed effect for time can work if you have multiple observations for different periods or if you only suspect a cyclical trend

-   More complicated autocorrelation structures can be modeled with a regression, and then OLS can be used on the residuals from that model

### ACF plots

ACF plots can be used to visualize autocorrelations. If the lagged correlation is above the blue line, then there's statistically meaningful autocorrelation.

```{r}

vdem|>
  filter(country_name=='Paraguay')|>
  arrange(year)|>
  filter(year >1990)|>
  mutate(diff_gdp = log(e_gdppc) - log(dplyr::lag(e_gdppc)))|>
  filter(!is.na(diff_gdp))|>
  with(acf(diff_gdp, lag.max = 5, plot = T))

```

```{r}


vdem_p<-vdem|>
  filter(country_name=='Paraguay')|>
  arrange(year)|>
  filter(year >1990)|>
  mutate(log_gdp = log(e_gdppc))|>
  filter(!is.na(e_gdppc))|>
  with(acf(log_gdp, lag.max = 5, plot = T))
```

### ACF plots: seasonality

This can make it much easier to spot seasonal trends as well:

```{r}

with(flights, acf(total_flights, lag.max=12, plot=T))


  

```

### ACF plots of residuals

```{r}

acf(differenced_model$residuals, lag.max=12, plot=T)
acf(ar_model$residuals, lag.max=12, plot=T)

```



```{r}
library(lme4)


set.seed(100)
N<-1000
ngroups<-10
group_intercepts<-c(rnorm(ngroups-1, mean=20, sd=1), 5)
names(group_intercepts) <-letters[1:ngroups]

groups<-sample(letters[1:ngroups], 
               replace=T, 
               prob = c(rep(.1, 9), .01),
               size=N)



x<-rnorm(N)
y<-group_intercepts[groups] + rnorm(N)
df<-data.frame(groups, x, y)

groupcounts<-df|>count(groups)
  


complete<-lm(y ~ 1, data=df)|>tidy(conf.int=TRUE)|>
  mutate(groups = 'pooled')

est<-complete$estimate[which(complete$term=="(Intercept)")]
nopool<- df|>
  group_by(groups)|>
  nest()|>
  mutate(fit = map(data, ~tidy(lm(y ~ 1, data=.x), conf.int=TRUE))
       
         )|>
  unnest(fit)|>
  select(-data)


pp<-lmer(y ~ 0 + (1|groups), data = df)

rfx<-data.frame(ranef(pp))|>
  mutate(grp = paste(grp))
#rfx_ci<-confint(pp, method = "boot", nsim = 500, boot.type = "perc")


data<-bind_rows(complete, nopool)|>
  mutate(type = factor(groups == "pooled", levels=c(TRUE, FALSE), 
                       labels = c("pooled", "not pooled")))



data|>
  filter(term == "(Intercept)")|>
  arrange(groups)|>
  left_join(groupcounts)|>
  ggplot(aes(x=groups, y=estimate, color=type, 
             ymin = conf.low, ymax=conf.high, label=n)) + 
  geom_point()  + 
  geom_hline(yintercept = est, lty=2) +
  geom_pointrange() +
  scale_color_manual(values=c('red', 'black')) +
  theme_bw() +
  geom_point(data=rfx, aes(x=grp, y=condval), 
             #position = position_nudge(x=0.5),
             color = 'blue',
             inherit.aes = FALSE) +
  coord_flip() 







```
